{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b3390a-82bd-4271-bf12-705d532349db",
   "metadata": {},
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numerical and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values in some of the columns. You want to build a pipeline that automates the feature\n",
    "engineering process and handles the missing values.\n",
    "\n",
    "Design a pipeline that includes the following steps\"\n",
    "\n",
    "1. Use an automated feature selection method to identify the important features in the datasetC\n",
    "2. Create a numerical pipeline that includes the following steps\"\n",
    "3. Impute the missing values in the numerical columns using the mean of the column valuesC\n",
    "4. Scale the numerical columns using standardisationC\n",
    "5. Create a categorical pipeline that includes the following steps\"\n",
    "6. Impute the missing values in the categorical columns using the most frequent value of the columnC\n",
    "7. One-hot encode the categorical columnsC\n",
    "8. Combine the numerical and categorical pipelines using a ColumnTransformerC\n",
    "9. Use a Random Forest Classifier to build the final modelC\n",
    "10. Evaluate the accuracy of the model on the test dataset.\n",
    "\n",
    "Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68e8ef-ca02-4dc4-a92c-73b7a3fc2f2a",
   "metadata": {},
   "source": [
    "\n",
    "Here's a step-by-step pipeline design that handles missing values, automates feature engineering, and builds a Random Forest Classifier model with feature selection, preprocessing for numerical and categorical features, and model evaluation. I'll walk through the pipeline and include Python code using libraries like scikit-learn for each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda89ae-a4df-40a0-b01e-70b6607bbe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Step 1: Load Necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## Step 2: Load the Dataset\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assuming 'target' is the label column\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "## Step 3: Automated Feature Selection\n",
    "\n",
    "# SelectFromModel to automatically select important features using Random Forest\n",
    "\n",
    "feature_selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "## Step 4: Create a Numerical Pipeline\n",
    "\n",
    "# Pipeline for numerical features\n",
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
    "    ('scaler', StandardScaler())  # Standardize the data (mean=0, std=1)\n",
    "])\n",
    "\n",
    "## Step 5: Create a Categorical Pipeline\n",
    "\n",
    "# Pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "## Step 6: Combine Pipelines Using ColumnTransformer\n",
    "# Define which columns are numerical and which are categorical\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Combine numerical and categorical pipelines\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "## Step 7: Create the Final Pipeline\n",
    "# Create the final pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Preprocessing step\n",
    "    ('feature_selection', feature_selector),  # Feature selection step\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Random Forest classifier\n",
    "])\n",
    "\n",
    "## Step 8: Train the Model\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "## Step 9: Evaluate the Model\n",
    "# Predict and evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0171e70a-6a51-47ff-8ed6-3218066d5f63",
   "metadata": {},
   "source": [
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9280cfc3-ccad-40e3-a24b-d6afa9b76db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "logistic_regression = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', random_forest),\n",
    "    ('lr', logistic_regression)\n",
    "], voting='hard')  # For majority voting\n",
    "\n",
    "# For soft voting (averaging probabilities), use `voting='soft'`\n",
    "\n",
    "# Create a pipeline with the VotingClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('voting_classifier', voting_clf)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb6677-c60b-4b22-a1c3-4acf5c29a0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
